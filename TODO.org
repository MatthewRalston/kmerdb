# Kmer DB

.kdb files should be debrujin graph databases
The initial prototype would be plaintext
The final prototype would be .bgzf format from biopython

* TODO arguments.method == "Biopython (has a FIXME in bin/kdb)
** Check this [[https://www.analyticsvidhya.com/blog/2019/05/beginners-guide-hierarchical-clustering/][link]]
** Needs a euclidean distance matrix

* Need an Rmd and a report directory that autopopulates a report
** 

* Priorities
** Connect this to meme suite
** 

* [[https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA][PCA]] (scikit-learn)
** Uses the LAPACK implementation
** 
* Manifold learning
** Isomap (derived from multidimensional scaling (MDS) or Kernel PCA)
*** Lower dimensional projectsion of the data preserving geodesic distances between all points
** (Modified) Locally Linear Embedding
*** Lower dimensional projection of the data preserving local neighborhood distances
*** locally_linear_embedding or LocallyLinearEmbedding with method="modified"
** t-SNE
*** While isomap, LLE, and variants are best tuited to unfold a single continuous low-dimensional manifold
*** t-SNE will focus on the local structure of the data and will tend to extract clustered local groups of samples.
*** This ability to group samples based on the local structure might be beneficial to visually disentangle a dataset that comprises several manifolds at once.

* Comment code
** TODO fileutil
** profile
** DONE index
   CLOSED: [2020-02-11 Tue 17:14]



* Bugs
** 0-length blocks
*** 307 0-length blocks out of 607 in Bsubtilis.kdb
*** 0-length block creation is too frequent, KDBWriter
*** Remember to change logger.warning in kdb.index to raise Exception
** Handle reads /fasta with 'N' (ambiguous base)
* index class
** need b-tree library
*** https://pythonhosted.org/BTrees/
** input dictionary
*** given a int/float I want fast access to all keys greater than or less than the int/float
*** e.g. { 345: [line offsets], 346: [lineoffsets} sorted by the int/float
*** The following searches for all values greater-than(min) or less-than(max), flattening
*** list(itertools.chain.from_iterable(btree.values(min=int/float)))
* kdb annotator class (reworked into index class and better metadata specification)
*** DONE First, further specify kdb record shape
    CLOSED: [2019-11-24 Sun 23:00]
*** DONE Second specify kdb metadata shape/parsing routines
    CLOSED: [2019-11-24 Sun 23:00]
*** Annotate bools, floats (probability), tags, ints (connectivity/degree)
**** Eulerian as a tag or a bool?
*** Index should be designed to rapidly filter tags, rapidly search/filter/narrow on ints
* Index function
** kmer id index : parse header offset (done?), then use readline + .tell() to get offset
** count index : b-tree
*** sort k-mers by counts (in memory, not on file), then create b-tree, leafs are k-mer file indices (above)
** tag : hash index
** float, int indices : similar to count index above6
* Documentation
** README
** Blog post + review of kmer tools
** Make note of R1/R2 reverse complement needs in strand-specific sequencing
*** maybe a nargs=* optional list for R2? FR strand specificity
*** This wouldn't accomodate RF library preps
*** Either way, add a note that trimming and reverse complementing the reads should be done prior

* Operations
** DONE Get all neighbors
   CLOSED: [2019-11-12 Tue 14:41]
*** Remove first/last letter, add one of the 3 other possible letters
*** 6 possible neighbors
** is_terminal = True if all neighbors of one direction have 0 count
** Eulerian walk (Maybe at the Python level and not the C-api)
*** Return a group of k-mers that have a complete walk

* DONE Format specification
  CLOSED: [2019-12-02 Mon 13:40]
** YAML header (first block) 
*** format version
*** choice of k
*** file name, sha256 checksums, number of reads, kmers added
*** comments
kdb_ver: 0.0.1
k: 14
files:
  - filename: 
    sha256: 
    md5: 
    total_reads: 
    total_kmers: 
    unique_kmers: 
  - filename: ...
comments:
** kmers (other blocks)
*** kmer id
*** count (exclude 0 count kmers?)
*** yaml metadata/neighboring k-mer ids
* toolkit
** DONE Reverse strand
   CLOSED: [2019-12-02 Mon 13:39]
** DONE utility functions
   CLOSED: [2019-12-02 Mon 13:39]
*** DONE translate kmers to/from binary encoding
    CLOSED: [2019-10-30 Wed 12:14]
*** DONE header validation
    CLOSED: [2019-11-12 Tue 14:32]
** DONE summary
   CLOSED: [2019-10-30 Wed 12:14]
*** print information from header
** DONE profile
   CLOSED: [2019-12-02 Mon 13:38]
*** VERIFY new profile is sum of individual profiles
**** for x in range(len(f.profile)):
****     final.profile[x] += f.profile[x]
*** closed
**** DONE kdb.file.checksums generates checksums of a file
     CLOSED: [2019-11-06 Wed 02:25]
**** DONE prof=array.array('H'); for x in range(4**k): prof.append(0)
     CLOSED: [2019-11-06 Wed 02:26]
**** DONE prof[sequenceToBinary(kmer)] += 1
     CLOSED: [2019-11-06 Wed 02:26]
**** DONE total_kmers += 1
     CLOSED: [2019-11-06 Wed 02:26]
**** DONE total_reads += 1
     CLOSED: [2019-11-06 Wed 02:26]
**** DONE unique_kmers = 4**k - prof.count(0)
     CLOSED: [2019-11-06 Wed 02:26]
**** DONE support multiple files
     CLOSED: [2019-11-12 Tue 14:31]
**** DONE generate streaming profile (file or [[https://gist.github.com/MatthewRalston/6641f45bdce19341f568264132b794de][S3 download to temp]])
     CLOSED: [2019-11-12 Tue 14:32]
**** DONE KDBReader.read_profile 
     CLOSED: [2019-11-12 Tue 14:31]
**** DONE KDBWriter.write_profile
     CLOSED: [2019-11-12 Tue 14:31]
** VERIFY similarity
*** cumulative formulas
**** these need to be calculated differently for efficiency/memory reasons
**** repetitive summation/multiplication and not direct to unit vector transformation
**** DONE 1. Pearson correlation coefficient of counts? of unit vector?
     CLOSED: [2019-11-07 Thu 13:03]
**** DONE 2. euclidean distance of unit vectors?
     CLOSED: [2019-11-07 Thu 13:03]
**** 3. sort by count of vector/index and Spearman
*** jaccard
**** presence/absence (k-mer is observed in both profiles? it's in the intersection
**** similar count within a tolerance... vs Spearman?
*** MUMi distance
** jsonify
*** transform the debrujin graph into json
** Partitioning experiment
*** Use khmer to partition reads from an example dataset
*** Similarity metrics between partition fastas and whole profile
*** Annotate kdb metadata to include Markov probabilities of single sequences to partition
*** How do we describe or select subgraphs based on the partition information?
**** Presence of Eulerian walk among partition AND if the eulerian walk extends too far into other partitions
**** Key reads AND k-mers involved in complex graph structures near partition bridges
**** Suggestions for deeper sequencing or skew in partition compositions to make up for low depth
**** Number of partition bridges vs subsampling
**** Number of partition bridges vs unique k-mer count / partition
**** Other metrics besides unique k-mer count
***** Overlap k-mer count
***** unique k-mers per total k-mers
***** unique k-mers per partitioned reads
*** How do we describe subgraph features worth considering, given the partition
**** Node connectivity stats
**** kdb filtering ( retrieve only k-mers with partition, connectivity, Markov probability cutoffs, participant in Eulerian walk)
** Other functions
*** Partitionizer (partition fasta and genomic fastas; completeness of each partition's capture of the ideal composite)
**** How much more data do I need from each partition to minimize bridges, maximize genomic coverage, and maximize orthogonality to other partitions
**** Given a partition fasta and a genomic fasta
**** Could estimate the sequencing depth and complexity required to minimize *most* partition bridges
**** Could also estimate the size and partitioning required to maximize partition orthogonality
*** Sampleizer (one genome fasta; dial up/back efforts in improving this partition/sampling)
**** Does my sampling protocol for this partition only have enough uniqueness to cover the one major walk, or is most of the data getting in the way of the other species at the current composite compositions?
**** How much of the genomic profile is covered by the partition?
**** At a certain orthogonality metric per sampling from the genomic fasta, does the amount of uniqueness orthogonality recovered by additional depth tend to clarify the partition, or obfuscate other operations on leading partitions?
*** Profilizer (all genome fastas; snapshot/metrics, as composite is improved)
**** Construct a perfect profile from all genomes and integrate
**** Similarities between individual profiles and perfect composite (Ideal distance metrics for each profile addition to perfect the composite)
**** Similarities between imperfect composite and perfect composite (How much orthogonality and completeness is currently recovered)
**** Similarities between imperfect partitions and perfect composite (How much orthogonality is lost due to current imperfect partitioning)
**** Similarities between imperfect composite and imperfect partitions (How much orthogonality is lost due to current imperfect partitioning)
*** walker (calculate Eulerian walks, i.e. walks that maximize path length under constrains (no node visited twice, etc.))
**** it's an optimization of some kind
**** under the constraint of 'no node visited twice'
**** maximize walk length (like the number of joins)
* Other functions
** chimera, duplications, transposon, contamination detection (kPAL)
** [[https://kpal.readthedocs.io/en/latest/method.html#distance-metrics][multiset distance/similarity (kPAL)]]
** Peak detection and modality analysis (single k-mer peak, low neighbors? broad k-mer abundance peaks?)
** k-mer spectrum plotting (ggplot? tsv?)
** sequencing error vs rare k-mer likelihoods (Kelley et all 2010 https://genomebiology.biomedcentral.com/articles/10.1186/gb-2010-11-11-r116)
** kdb filter for repetitive motifs/sequences?? 
** replace header (kdb header replace example.kdb example.yaml)
*** Leaving the count fields at 0 is okay, should recompute anyway
*** If the count fields are non-zero, then assume the values are correct

* Report
** How does sparseness scale linearly with the choice of k
** What is the appropriate distribution for k-mer counts
** Vanila (no-metadata) Profile generation time
*** Runtime vs reads (fasta, fastq)
*** Runtime vs filesize 
*** Compare slopes from regression to determine if profiles can be generated from fasta files faster
** How do profiles from WGS, simulated Illumina reads, and the assembled genome differ?
** Is there good separation Markov-chain probabilities of sequences from different species against a profile?
